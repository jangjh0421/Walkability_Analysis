{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Required for API calls\n",
        "import json\n",
        "import requests\n",
        "import itertools\n",
        "import googlemaps\n",
        "\n",
        "# Required for data preprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import geopandas as gpd\n",
        "\n",
        "# Required for training an AI model\n",
        "from shapely.geometry import Point, LineString\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score,classification_report"
      ],
      "metadata": {
        "id": "BzFQ0u39oIUk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#_______________________________________________\n",
        "key = \"GOOGLE MAPS API KEY\"\n",
        "OPENAI_API_KEY = 'OPEN AI API KEY'\n",
        "\n",
        "# Paths to your shapefiles\n",
        "road_shapefile_path = 'ABSOLUTE PATH TO THE ROAD NETWORK FILE'\n",
        "polygon_shapefile_path = 'ABSOLUTE PATH TO SHAPE FILES'\n",
        "#_______________________________________________"
      ],
      "metadata": {
        "id": "as_0BTrmv2wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the random state seed value for a reproducible output\n",
        "seed = 1008781695"
      ],
      "metadata": {
        "id": "t4ip2H_xpGnY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"/content/drive/MyDrive/sentiment_yelp/customer_reviews_binary_21000.csv\")"
      ],
      "metadata": {
        "id": "ICzi0e0koWnH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(dataset[\"Comment\"], dataset[\"Sentiment\"], train_size=0.7, random_state=seed)"
      ],
      "metadata": {
        "id": "z-gqf6JlogRC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SInce AI model takes numeric inputs only, we have to vectorize every strings\n",
        "vectorizer = CountVectorizer()\n",
        "x_train_vec = vectorizer.fit_transform(x_train)\n",
        "x_test_vec = vectorizer.transform(x_test)"
      ],
      "metadata": {
        "id": "OWoQyh0ZpqFH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a classifier model and training it\n",
        "rf_clf1 = RandomForestClassifier(n_estimators = 10,\n",
        "                                max_depth = 6,\n",
        "                                min_samples_leaf = 5,\n",
        "                                min_samples_split = 8,\n",
        "                                random_state = seed,\n",
        "                                n_jobs = -1)\n",
        "rf_clf1.fit(x_train_vec, y_train)\n",
        "pred = rf_clf1.predict(x_test_vec)\n",
        "print('Prediction Accuracy: {:.4f}'.format(accuracy_score(y_test,pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbG9xd6Z3qZs",
        "outputId": "5eca2a1c-45b6-498e-ff56-64008dc4bad6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction Accuracy: 0.9637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking its performance\n",
        "y_pred = rf_clf1.predict(x_test_vec)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "print(\"accuracy\",accuracy)\n",
        "Report = classification_report(y_test,y_pred)\n",
        "print(Report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfwRXGrypubK",
        "outputId": "49124921-07e5-4edd-b9f4-8982bc4afbf6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.9636565624504047\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       1.00      0.93      0.96      3175\n",
            "    Positive       0.93      1.00      0.96      3126\n",
            "\n",
            "    accuracy                           0.96      6301\n",
            "   macro avg       0.97      0.96      0.96      6301\n",
            "weighted avg       0.97      0.96      0.96      6301\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing the sentiment analysis with Google Maps only\n",
        "\n",
        "# Initialize a set to store sentiment scores\n",
        "score_set = set()\n",
        "\n",
        "gmaps = googlemaps.Client(key=key)\n",
        "\n",
        "def extract_intersections_within_polygon(road_shapefile, polygon_shapefile):\n",
        "    try:\n",
        "        print(\"Loading road shapefile...\")\n",
        "        roads_gdf = gpd.read_file(road_shapefile)\n",
        "        print(f\"Road shapefile loaded successfully. Number of geometries: {len(roads_gdf)}\")\n",
        "\n",
        "        print(\"Loading polygon shapefile...\")\n",
        "        polygon_gdf = gpd.read_file(polygon_shapefile)\n",
        "        print(f\"Polygon shapefile loaded successfully. Number of geometries: {len(polygon_gdf)}\")\n",
        "\n",
        "        # Reproject both shapefiles to EPSG:4326\n",
        "        print(\"Reprojecting road shapefile to EPSG:4326...\")\n",
        "        roads_gdf = roads_gdf.to_crs(epsg=4326)\n",
        "        print(\"Reprojecting polygon shapefile to EPSG:4326...\")\n",
        "        polygon_gdf = polygon_gdf.to_crs(epsg=4326)\n",
        "        print(\"Reprojection completed.\")\n",
        "\n",
        "        # Ensure the polygon shapefile contains one polygon\n",
        "        if len(polygon_gdf) != 1:\n",
        "            print(\"The polygon shapefile should contain exactly one polygon.\")\n",
        "            return []\n",
        "\n",
        "        polygon = polygon_gdf.geometry.iloc[0]\n",
        "\n",
        "        # Ensure the road geometries are lines\n",
        "        roads_gdf = roads_gdf[roads_gdf.geometry.type == 'LineString']\n",
        "        print(f\"Filtered LineString geometries. Number of LineString geometries: {len(roads_gdf)}\")\n",
        "\n",
        "        # Filter the road lines that intersect with the polygon\n",
        "        roads_gdf = roads_gdf[roads_gdf.intersects(polygon)]\n",
        "        print(f\"Filtered roads that intersect with the polygon. Number of intersecting roads: {len(roads_gdf)}\")\n",
        "\n",
        "        # Create an empty list to store the intersections\n",
        "        intersections = []\n",
        "\n",
        "        # Compare each line with every other line to find intersections within the polygon\n",
        "        total_combinations = len(roads_gdf) * (len(roads_gdf) - 1) // 2\n",
        "        print(f\"Total number of line combinations to check: {total_combinations}\")\n",
        "\n",
        "        count = 0\n",
        "        for line1, line2 in itertools.combinations(roads_gdf.geometry, 2):\n",
        "            count += 1\n",
        "            if count % 1000 == 0:\n",
        "                print(f\"Checked {count} / {total_combinations} combinations\")\n",
        "\n",
        "            if line1.intersects(line2):\n",
        "                intersection = line1.intersection(line2)\n",
        "                if intersection.geom_type == 'Point' and polygon.contains(intersection):\n",
        "                    intersections.append(intersection)\n",
        "                elif intersection.geom_type == 'MultiPoint':\n",
        "                    for point in intersection.geoms:\n",
        "                        if polygon.contains(point):\n",
        "                            intersections.append(point)\n",
        "\n",
        "        # Extract the coordinates of the intersections\n",
        "        coordinates = [(point.y, point.x) for point in intersections]  # Latitude and Longitude\n",
        "        print(f\"Number of intersections found: {len(coordinates)}\")\n",
        "\n",
        "        return coordinates\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return []\n",
        "\n",
        "def save_intersections_to_txt(coordinates, output_file):\n",
        "    try:\n",
        "        print(\"Saving intersections to text file...\")\n",
        "        with open(output_file, 'w') as f:\n",
        "            for lat, lon in coordinates:\n",
        "                f.write(f\"{lat}, {lon}\\n\")\n",
        "        print(f\"Intersections saved to {output_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while saving to file: {e}\")\n",
        "\n",
        "def perform_nearby_search(coordinates, radius, polygon, place_ids_set, reviews_list):\n",
        "    try:\n",
        "        print(\"Performing Nearby Search...\")\n",
        "\n",
        "        for lat, lon in coordinates:\n",
        "            params = {\n",
        "                'location': f'{lat},{lon}',\n",
        "                'radius': radius,  # Radius in meters\n",
        "                'key': key\n",
        "            }\n",
        "\n",
        "            url = 'https://maps.googleapis.com/maps/api/place/nearbysearch/json'\n",
        "            response = requests.get(url, params=params)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                places_result = response.json().get('results', [])\n",
        "                for place in places_result:\n",
        "                    place_location = place['geometry']['location']\n",
        "                    place_point = Point(place_location['lng'], place_location['lat'])\n",
        "                    if polygon.contains(place_point):\n",
        "                        place_ids_set.add(place['place_id'])\n",
        "\n",
        "                        # Fetch place details including reviews\n",
        "                        place_id = place['place_id']\n",
        "                        details_params = {\n",
        "                            'place_id': place_id,\n",
        "                            'fields': 'rating,reviews',\n",
        "                            'key': key\n",
        "                        }\n",
        "                        details_url = 'https://maps.googleapis.com/maps/api/place/details/json'\n",
        "                        details_response = requests.get(details_url, params=details_params)\n",
        "\n",
        "                        if details_response.status_code == 200:\n",
        "                            place_details = details_response.json().get('result', {})\n",
        "                            if 'reviews' in place_details:\n",
        "                                for review in place_details['reviews']:\n",
        "                                    reviews_list.append(review['text'])\n",
        "            else:\n",
        "                print(f\"Error {response.status_code}: {response.text}\")\n",
        "\n",
        "        print(f\"Number of unique Place IDs found within the polygon: {len(place_ids_set)}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during Nearby Search: {e}\")\n",
        "\n",
        "# Output file path\n",
        "intersections_file_path = 'intersections.txt'\n",
        "places_file_path = 'places.txt'\n",
        "\n",
        "# Radius for Nearby Search (in meters)\n",
        "radius = 400\n",
        "\n",
        "# Extract intersections within the polygon\n",
        "print(\"Starting intersection extraction...\")\n",
        "intersections = extract_intersections_within_polygon(road_shapefile_path, polygon_shapefile_path)\n",
        "\n",
        "# Save intersections to a text file\n",
        "if intersections:\n",
        "    save_intersections_to_txt(intersections, intersections_file_path)\n",
        "\n",
        "    # Load the polygon shapefile again to get the polygon geometry\n",
        "    polygon_gdf = gpd.read_file(polygon_shapefile_path)\n",
        "    polygon_gdf = polygon_gdf.to_crs(epsg=4326)\n",
        "    polygon = polygon_gdf.geometry.iloc[0]\n",
        "\n",
        "    # Perform Nearby Search and save unique Place IDs to a set\n",
        "    unique_place_ids = set()\n",
        "    reviews_list = []\n",
        "\n",
        "    perform_nearby_search(intersections, radius, polygon, unique_place_ids, reviews_list)\n",
        "\n",
        "    # Print all reviews\n",
        "    print(\"All Reviews:\")\n",
        "    sum_score = 0\n",
        "    for review in tqdm(reviews_list, desc=\"Processing reviews\"):\n",
        "        r_vec = vectorizer.transform([review])\n",
        "        pred_sentiment = rf_clf1.predict(r_vec)\n",
        "        if pred_sentiment[0] == 'Positive':\n",
        "            sum_score += 1\n",
        "\n",
        "    print(\"\\nSentiment Score: \" + str(sum_score / len(reviews_list)))\n",
        "\n",
        "else:\n",
        "    print(\"No intersections found within the polygon.\")\n"
      ],
      "metadata": {
        "id": "MuJYHEiA4INt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a184a99f-50ac-4162-dd59-3f8fdf960de9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googlemaps\n",
            "  Downloading googlemaps-4.10.0.tar.gz (33 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests<3.0,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from googlemaps) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (2024.7.4)\n",
            "Building wheels for collected packages: googlemaps\n",
            "  Building wheel for googlemaps (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googlemaps: filename=googlemaps-4.10.0-py3-none-any.whl size=40712 sha256=edb24651b8b0ac64b29bdb996d73bc6fbc58a62d6a113ae2436e16963343ca73\n",
            "  Stored in directory: /root/.cache/pip/wheels/17/f8/79/999d5d37118fd35d7219ef57933eb9d09886c4c4503a800f84\n",
            "Successfully built googlemaps\n",
            "Installing collected packages: googlemaps\n",
            "Successfully installed googlemaps-4.10.0\n",
            "Collecting geopandas\n",
            "  Downloading geopandas-1.0.1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.25.2)\n",
            "Collecting pyogrio>=0.7.2 (from geopandas)\n",
            "  Downloading pyogrio-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas) (24.1)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.0.3)\n",
            "Collecting pyproj>=3.3.0 (from geopandas)\n",
            "  Downloading pyproj-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
            "Collecting shapely>=2.0.0 (from geopandas)\n",
            "  Downloading shapely-2.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas) (2024.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyogrio>=0.7.2->geopandas) (2024.7.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->geopandas) (1.16.0)\n",
            "Downloading geopandas-1.0.1-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.6/323.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyogrio-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproj-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shapely-2.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: shapely, pyproj, pyogrio, geopandas\n",
            "Successfully installed geopandas-1.0.1 pyogrio-0.9.0 pyproj-3.6.1 shapely-2.0.5\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (2.0.5)\n",
            "Requirement already satisfied: numpy<3,>=1.14 in /usr/local/lib/python3.10/dist-packages (from shapely) (1.25.2)\n",
            "Starting intersection extraction...\n",
            "Loading road shapefile...\n",
            "Road shapefile loaded successfully. Number of geometries: 307547\n",
            "Loading polygon shapefile...\n",
            "Polygon shapefile loaded successfully. Number of geometries: 1\n",
            "Reprojecting road shapefile to EPSG:4326...\n",
            "Reprojecting polygon shapefile to EPSG:4326...\n",
            "Reprojection completed.\n",
            "Filtered LineString geometries. Number of LineString geometries: 307547\n",
            "Filtered roads that intersect with the polygon. Number of intersecting roads: 2\n",
            "Total number of line combinations to check: 1\n",
            "Number of intersections found: 0\n",
            "No intersections found within the polygon.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tdvrD9izVOab"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}